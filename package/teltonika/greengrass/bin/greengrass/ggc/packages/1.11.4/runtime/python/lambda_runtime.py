# -*- coding: utf-8 -*-
#
# Copyright 2010-2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
import argparse
import base64
import json
import logging
import signal
import sys
import traceback
import decimal
from collections import namedtuple

from greengrass_common import common_log_appender
from greengrass_common.function_arn_fields import FunctionArnFields
from greengrass_common.env_vars import MY_FUNCTION_ARN, ENCODING_TYPE,\
    GGC_MAX_INTERFACE_VERSION, AUTH_TOKEN, GG_DAEMON_PORT
from greengrass_common.encoding_type import EncodingType
from greengrass_common.parse_version import parse_version
from greengrass_ipc_python_sdk.ipc_client import IPCClient, IPCException, WorkItem
from greengrass_ipc_python_sdk.utils.exponential_backoff import retry

if sys.version_info.major < 3:
    import imp
else:
    import importlib

local_cloudwatch_handler = common_log_appender.LocalwatchLogHandler()
local_cloudwatch_handler.setFormatter(logging.Formatter(common_log_appender.LOCALWATCH_FORMAT))

runtime_logger = logging.getLogger(__name__)

env_vars = dict([('MY_FUNCTION_ARN', MY_FUNCTION_ARN),
                 ('AWS_CONTAINER_AUTHORIZATION_TOKEN', AUTH_TOKEN),
                 ('ENCODING_TYPE', ENCODING_TYPE),
                 ('GGC_MAX_INTERFACE_VERSION', GGC_MAX_INTERFACE_VERSION),
                 ('GG_DAEMON_PORT', GG_DAEMON_PORT)])


def _import_module(module):
    """
    Simple wrapper function for importing modules.
    """
    # Use the legacy 'imp' package for importing modules on Python2 rather than
    # the newer 'importlib' package. 'importlib' was backported to Python2.7,
    # but some customers do not have it available.
    if sys.version_info.major < 3:
            path = None
            fp = None
            mod = None
            for x in module.split('.'):
                try:
                    if path is not None:
                        path = [path]
                    fp, path, descr = imp.find_module(x, path)
                    mod = imp.load_module(module.split('.')[-1], fp, path, descr)
                finally:
                    if fp:
                        fp.close()
            if not mod:
                raise ValueError('Unable to load module {}'.format(module))
    else:
        mod = importlib.import_module(module)
    return mod


class LambdaRuntime:
    """
    Simple runtime for starting and pinning long-running functions. All log entries generated by
    the python runtime go to common_log_appender.local_cloudwatch_handler. The stdio and root logger
    of customer's lambda go to handler_for_customer, which writes to a separate log.
    """

    def __init__(self, endpoint='localhost', port=8000):
        """
        :param endpoint: Endpoint used to connect to IPC.
        :type endpoint: str

        :param port: Port number used to connect to the :code:`endpoint`.
        :type port: int
        """
        self.local_cloudwatch_log_handler = local_cloudwatch_handler

        self.stdout_log_writer = common_log_appender.StdioLogWriter(logging.INFO, self.local_cloudwatch_log_handler)
        self.stdout_redirect = _StdoutRedirect(self.stdout_log_writer)

        self.stderr_log_writer = common_log_appender.StdioLogWriter(logging.ERROR, self.local_cloudwatch_log_handler)
        self.stderr_redirect = _StderrRedirect(self.stderr_log_writer)

        # root logger also emits log to the same destination as lambda function based on:
        # http://docs.aws.amazon.com/lambda/latest/dg/python-logging.html
        self.root_logger = logging.getLogger()
        self.root_logger.addHandler(self.local_cloudwatch_log_handler)
        # set to the lowest possible level so all log messages will be sent to local cloudwatch handler
        self.root_logger.setLevel(logging.DEBUG)

        check_env_vars(env_vars)
        self.function_arn = MY_FUNCTION_ARN
        self.encoding_type = ENCODING_TYPE
        self.ipc = IPCClient(endpoint=endpoint)
        check_interface_version()

        arn_fields = MY_FUNCTION_ARN.split(':')
        # transform lambda ARN into the format: region/account-id/function-name
        if len(arn_fields) == 7:
            # lambda ARN with no alias nor version
            # arn:aws:lambda:region:account-id:function:function-name
            component_name = arn_fields[3:5]
            component_name.append(arn_fields[-1])
            component_name = '/'.join(component_name)
        else:
            # lambda ARN with alias or version
            # arn:aws:lambda:region:account-id:function:function-name:version
            component_name = arn_fields[3:5]
            component_name.append(arn_fields[-2])
            component_name = '/'.join(component_name)

    def import_handler(self, function_handler):
        """
        :param function_handler: Handler function that is called to process incoming work items
        :type function_handler: function
        """
        if callable(function_handler):
            self.handler = function_handler
        else:
            try:
                # Dynamically load Lambda handler
                handler_path = function_handler.split('.')
                handler_function = handler_path[-1]
                handler_file = handler_path[:-1]

                # the handler exposes a `write(data)` method so that when a customer lambda
                # prints to stdout or stderr, the message will be sent to local Cloudwatch
                with self.stdout_redirect, self.stderr_redirect:
                    m = _import_module(".".join(handler_file))

                self.handler = getattr(m, handler_function)

            except Exception as e:
                runtime_logger.critical('Failed to import handler function "{}" '
                                        'due to exception: {}'.format(function_handler, str(e)))
                raise e

    def start(self):
        """
        Start running :code:`handler` function and feed work items to it as they come.
        """
        runtime_logger.info('Running [{}]'.format(self.function_arn))

        try:
            while True:
                self._run_once()
        except Exception as e:
            runtime_logger.error('Failed to execute _run_once() due to exception: {}'.format(str(e)))

    @retry(0.001, 50, 2, 500, 10, 3, True)
    def _run_once(self):
        try:
            work = self.ipc.get_work(self.function_arn)
        except IPCException as e:
            runtime_logger.info('Failed to get work item due to exception: {}'.format(str(e)))
            raise

        invocation_id = work.invocation_id

        if self.encoding_type == EncodingType.Binary:
            event = work.payload
        elif self.encoding_type == EncodingType.JSON:
            if work.payload is None or len(work.payload) == 0:
                event = json.loads('""')
            else:
                try:
                    event = json.loads(work.payload)
                except ValueError as e:
                    error_string = 'Cannot parse given invoke payload as JSON: {}'.format(work.payload)
                    self.ipc.post_handler_err(self.function_arn, invocation_id, error_string)
                    runtime_logger.error(error_string)
                    return
        else:
            error_string = 'Encoding type {} is invalid, only "binary" or "json" are supported'.format(self.encoding_type)
            self.ipc.post_handler_err(self.function_arn, invocation_id, error_string)
            runtime_logger.error(error_string)
            return

        client_context = work.client_context

        context = _Context(self.function_arn, invocation_id, client_context)

        try:
            with self.stdout_redirect, self.stderr_redirect:
                if self.encoding_type == EncodingType.Binary:
                    result = self.handler(event, context)
                else:
                    result = to_json(self.handler(event, context))

        except Exception as e:
            handler_err = '{}'.format(e)
            self.ipc.post_handler_err(self.function_arn, invocation_id, handler_err)
            trace_back = traceback.extract_tb(sys.exc_info()[2])
            # removes the first entry in the stacktrace where lambda_runtime.py shows up
            stack_trace = ''.join(traceback.format_list(trace_back[1:]))
            # log the error message to customer's log.
            self.root_logger.error('Handler function failed with exception: {}, stacktrace: {}'.format(e, stack_trace))
            return

        finally:
            for handler in self.root_logger.handlers:
                handler.flush()

        try:
            work_result = WorkItem(invocation_id=invocation_id, payload=result, client_context=b'')
            self.ipc.post_work_result(self.function_arn, work_result)
        except Exception as e:
            runtime_logger.error('Failed to post work results due to exception: {}'.format(str(e)))
            raise


ClientContext = namedtuple(
    'ClientContext',
    ['client', 'custom', 'env']
)

ClientContextClient = namedtuple(
    'ClientContextClient',
    ['installation_id', 'app_title', 'app_version_name', 'app_version_code', 'app_version_package_name']
)


class _StdRedirect:
    @property
    def _fd_name(self):
        raise NotImplementedError()

    def __init__(self, file_like_object):
        self._file = file_like_object

    def __enter__(self):
        # Save the original std file descriptor so it can be restored later
        self._orig_fd = getattr(sys, self._fd_name)

        # Change the std file descriptor to our temporary file-like object
        setattr(sys, self._fd_name, self._file)

    def __exit__(self, *args):
        # Restore the std file descriptor to its original value
        setattr(sys, self._fd_name, self._orig_fd)


class _StdoutRedirect(_StdRedirect):
    @property
    def _fd_name(self):
        return 'stdout'


class _StderrRedirect(_StdRedirect):
    @property
    def _fd_name(self):
        return 'stderr'


# Lambda docs: http://docs.aws.amazon.com/lambda/latest/dg/python-context-object.html

class _Context:
    def __init__(self, function_arn, invocation_id, client_context_encoded=None):
        arn_fields = FunctionArnFields(function_arn)

        self.invoked_function_arn = function_arn
        self.function_name = arn_fields.name
        self.function_version = arn_fields.qualifier
        self.aws_request_id = invocation_id

        if client_context_encoded:
            client_context_map = json.loads(base64.b64decode(client_context_encoded).decode('utf-8'))
            client_context_client = None
            if 'client' in client_context_map:
                client_context_client = ClientContextClient(**client_context_map['client'])
            client_context_custom = None
            if 'custom' in client_context_map:
                client_context_custom = client_context_map['custom']
            client_context_env = None
            if 'env' in client_context_map:
                client_context_env = client_context_map['env']

            self.client_context = ClientContext(
                client_context_client,
                client_context_custom,
                client_context_env
            )
        else:
            self.client_context = None

        self.identity = None

        # skip self.memory_limit_in_mb
        # skip self.log_group_name
        # skip self.log_stream_name


def parse_args():
    parser = argparse.ArgumentParser()

    parser.add_argument('--handler', type=str, required=True, help='Handler defined for lambda function')
    args, unknown = parser.parse_known_args()
    return args


def to_json(obj):
    return json.dumps(obj, default=decimal_serializer, ensure_ascii=False)


def decimal_serializer(o):
    if isinstance(o, decimal.Decimal):
        return number_str(o)
    raise TypeError(repr(o) + " is not JSON serializable")


def check_env_vars(vars):
    for key in vars:
        if not vars[key]:
            err = Exception('Missing {} environment variable'.format(key))
            runtime_logger.error(err)
            raise err


def compare_version(sdk_IV, max_IV):
    sdk_IV_major, sdk_IV_minor = parse_version(sdk_IV)
    max_IV_major, max_IV_minor = parse_version(max_IV)
    if int(sdk_IV_major) != int(max_IV_major) or sdk_IV_minor > max_IV_minor:
        return False
    return True


def check_interface_version():
    try:
        greengrass_sdk = _import_module('greengrasssdk')
        version = greengrass_sdk.INTERFACE_VERSION

    except ImportError:
        # SDK not used by user lambda, skipping check
        return True
    except AttributeError:
        # Old SDK, default to default interface version number
        version = '1.0'
        pass

    max_version = GGC_MAX_INTERFACE_VERSION
    if not compare_version(version, max_version):
        err = ValueError('There was a version incompatibility between the Greengrass SDK used ' +
                         'by your function [{}] and the Greengrass Core. Please visit '.format(MY_FUNCTION_ARN) +
                         'the AWS Greengrass Developer Guide for version compatibility information')
        raise err


class number_str(float):
    def __init__(self, o):
        self.o = o


class SignalHandler():
    def __init__(self, signal):
        self._signal = signal

    @staticmethod
    def _handler(signum, frame):
        runtime_logger.info('Caught signal {}. Stopping runtime.'.format(signum))
        sys.exit(0)

    def install_handler(self):
        signal.signal(self._signal, SignalHandler._handler)


def main():
    SignalHandler(signal.SIGTERM).install_handler()

    args = parse_args()
    try:
        runtime = LambdaRuntime()
        runtime.import_handler(args.handler)
    except Exception as e:
        runtime_logger.critical('Failed to initialize Lambda runtime '
                                'due to exception: {}'.format(str(e)))
        sys.exit(1)

    runtime.start()


if __name__ == '__main__':
    main()
